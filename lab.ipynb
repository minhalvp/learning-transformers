{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32 # how many independent sequences will we process in parallel?\n",
    "block_size = 64 # what is the maximum context length for predictions?\n",
    "epochs = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 8\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# load json file alex.json\n",
    "with open('alex.json', encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all message contents into a single string\n",
    "text = '\\n'.join([f\"{m['author']['name']}:{m['content']}\" for m in data[\"messages\"]])\n",
    "# write text to a file alex.txt\n",
    "with open('alex.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([769508])\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('alex.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sp.encode_as_ids(text)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple transformer model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.426038 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init(\n",
    "    project=\"nanogpt-testing\",\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_layer\": n_layer,\n",
    "        \"n_head\": n_head,\n",
    "        \"n_embd\": n_embd,\n",
    "        \"block_size\": block_size,}\n",
    ")\n",
    "for iter in range(epochs):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == epochs - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    wandb.log({\"loss\": loss})\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OpTiMiStC:I'm different will bvpnilonitys one\n",
      "Medori:actuallyswogde\n",
      "Medori:2 minutuubled'>3 calouse numbers\n",
      "Medori:Pine detet\n",
      "OpTiMiStC:Yeah\n",
      "Medori:i love started using by life\n",
      "Medori:what is a rn\n",
      "Medori:Yh\n",
      "Medori:Imellist that pain colla\n",
      "Medori:Got nice assk time just fectly year\n",
      "OpTiMiStC:Aprop for atlinor\n",
      "OpTiMiStC:Just zAV you sto composy just mum at the worstly ethan\n",
      "OpTiMiStC:cody is doing\n",
      "OpTiMiStC:is the same\n",
      "OpTiMiStC:when we home\n",
      "OpTiMiStC:We don't her swead I cum not gonna uplot scores\n",
      "OpTiMiStC:You could\n",
      "OpTiMiStC:Honestly give a fever\n",
      "Medori:When u think it\n",
      "OpTiMiStC:Like autoi rlly remember,1 you play sent apposible in a diffebul littling\n",
      "Medori:I was finitially spit network chemistry\n",
      "OpTiMiStC:i be thinking under u get complity an english time to pretty into are a clips the so chem\n",
      "OpTiMiStC:\n",
      "Medori:oh yh way way tmny for midy print\n",
      "Medori:huhh\n",
      "Medori:How\n",
      "OpTiMiStC:https://youtu.be/V7q0k5A\n",
      "OpTiMiStC:\n",
      "OpTiMiStC:oh I start this was not much by arough\n",
      "OpTiMiStC:bro that is a lot of paper\n",
      "OpTiMiStC:of hanoury shit\n",
      "OpTiMiStC:that physics intoron\n",
      "OpTiMiStC:* round\n",
      "Medori:i c\n",
      "Medori:d10mb like daming\n",
      "Medori:lmao\n",
      "Medori:honestly did just wonT every did that him\n",
      "OpTiMiStC:yeah i won't it\n",
      "OpTiMiStC:also it done it\n",
      "OpTiMiStC:in a boomi4\n",
      "OpTiMiStC:there\n",
      "Medori:yh it the tricle doing the polar librarificx and with be secting that used\n",
      "Medori:lmao\n",
      "OpTiMiStC:https://youtu.be/2D77HTFSU\n",
      "Medori:how bring something\n",
      "OpTiMiStC:im gonna good tentbooominm\n",
      "OpTiMiStC:she spec assessment\n",
      "OpTiMiStC:email super hight how we like 3\n",
      "OpTiMiStC:im nglsparing cloody\n",
      "OpTiMiStC:https://youtu.be/AqHzOE6p?o0Y\n",
      "Medori:this much none you rawa\n",
      "OpTiMiStC:and that be any so us\n",
      "Medori:thats 1/3\n",
      "OpTiMiStC:the talked about\n",
      "Medori:bruh i thought it students\n",
      "OpTiMiStC:wait's hard\n",
      "OpTiMiStC:yknow fpz fucking being rn\n",
      "Medori:thats balls\n",
      "OpTiMiStC:lmao\n",
      "OpTiMiStC:look im saiding irl\n",
      "Medori:it wud the end\n",
      "OpTiMiStC:idk\n",
      "OpTiMiStC:she going high practics of cs\n",
      "OpTiMiStC: browder this cincle only event\n",
      "OpT\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'bigmodel.pt')\n",
    "\n",
    "# import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.MHA = nn.MultiheadAttention(n_embd, n_head, dropout=dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        self.MHA(x,x,x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.5387e-01, -9.0065e-01, -1.2124e+00,  ..., -6.6374e-01,\n",
       "          -1.0894e+00, -5.8394e-01],\n",
       "         [-1.0988e+00, -3.0963e-01, -1.4654e+00,  ..., -9.4405e-01,\n",
       "           1.6175e+00,  1.5655e+00],\n",
       "         [ 4.5148e-01, -1.3236e+00,  2.4697e-02,  ..., -4.9402e-01,\n",
       "           6.2258e-02,  1.1916e+00],\n",
       "         ...,\n",
       "         [-3.5254e-01, -1.0588e+00,  1.2127e+00,  ..., -2.6041e-01,\n",
       "           3.1462e-01, -2.7874e-01],\n",
       "         [-1.5985e+00,  7.2194e-01,  6.2852e-01,  ...,  1.1886e+00,\n",
       "           7.7472e-02,  4.6995e-01],\n",
       "         [-3.2228e-01,  9.5099e-01, -2.0557e+00,  ...,  6.7635e-01,\n",
       "           1.0454e+00, -1.1562e-01]],\n",
       "\n",
       "        [[ 2.0435e-01, -2.9111e-01, -7.0913e-01,  ..., -5.2609e-01,\n",
       "          -4.4271e-01, -2.8485e-01],\n",
       "         [-1.4839e+00,  8.5877e-01, -7.2787e-02,  ...,  1.8995e+00,\n",
       "          -1.4642e-01,  2.2801e-01],\n",
       "         [-7.6403e-01, -1.1333e+00, -3.4127e-01,  ..., -7.3189e-01,\n",
       "          -3.0177e-01,  3.3670e-02],\n",
       "         ...,\n",
       "         [-1.4567e-01,  7.4791e-01, -1.4270e+00,  ...,  3.4310e-01,\n",
       "          -7.8337e-01, -4.1308e-02],\n",
       "         [ 5.1900e-01,  6.0940e-01, -1.1096e+00,  ..., -6.6244e-01,\n",
       "          -1.4179e+00, -1.8320e+00],\n",
       "         [-3.5609e-01,  7.8695e-01,  1.0555e+00,  ...,  1.5213e+00,\n",
       "          -4.5708e-01,  1.0274e+00]],\n",
       "\n",
       "        [[ 1.2083e+00, -1.2835e+00,  2.1937e-01,  ...,  7.9144e-01,\n",
       "          -1.4350e+00, -2.6934e-01],\n",
       "         [-1.1842e-02, -6.5252e-01, -9.1578e-01,  ...,  2.5007e-01,\n",
       "          -4.1287e-03, -8.9839e-01],\n",
       "         [-1.7076e+00,  3.6826e-01,  1.2312e+00,  ..., -1.5318e+00,\n",
       "           9.8054e-02,  6.1601e-03],\n",
       "         ...,\n",
       "         [-6.1075e-01, -6.9206e-01,  1.0350e+00,  ...,  7.9576e-01,\n",
       "          -6.0745e-01,  6.0691e-01],\n",
       "         [ 1.1263e-03, -7.6303e-01,  7.3217e-01,  ..., -1.2518e+00,\n",
       "          -9.8614e-01,  1.0032e+00],\n",
       "         [ 7.9136e-02, -6.8246e-02,  3.1473e-01,  ..., -7.5664e-01,\n",
       "           1.2892e+00,  2.2191e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.1138e+00,  8.3306e-03, -1.1221e-01,  ...,  4.6919e-01,\n",
       "           1.3096e+00, -3.2563e-01],\n",
       "         [ 2.2721e+00,  9.4791e-01, -6.3881e-01,  ...,  5.5512e-01,\n",
       "          -1.2808e+00,  1.7393e+00],\n",
       "         [ 1.4545e+00,  2.7859e-01, -1.3526e+00,  ..., -2.5488e-01,\n",
       "           3.6746e-01,  1.4888e+00],\n",
       "         ...,\n",
       "         [ 5.5044e-01,  1.8235e+00, -1.1271e+00,  ...,  9.1952e-01,\n",
       "          -5.3620e-01,  9.3828e-01],\n",
       "         [-5.3910e-01,  1.3249e+00,  9.3261e-01,  ..., -8.9558e-01,\n",
       "          -1.0057e+00, -1.5857e-01],\n",
       "         [-3.0217e-01,  1.4923e+00, -9.0269e-01,  ...,  5.7198e-01,\n",
       "           1.4898e-01,  7.6218e-02]],\n",
       "\n",
       "        [[ 8.5689e-01, -5.6053e-01,  1.3386e-01,  ..., -5.5095e-01,\n",
       "          -1.3244e+00, -1.2643e-01],\n",
       "         [ 1.3115e+00, -7.1476e-01,  2.1866e-02,  ...,  1.3861e+00,\n",
       "           6.2792e-01, -2.0480e-01],\n",
       "         [-5.7256e-01, -4.6793e-01, -6.2020e-01,  ...,  5.2720e-02,\n",
       "          -8.2568e-01,  2.8347e-01],\n",
       "         ...,\n",
       "         [-3.1829e-01,  2.5709e+00, -6.6359e-01,  ...,  1.0617e+00,\n",
       "           2.2660e+00, -3.5156e-01],\n",
       "         [-3.2108e-01,  1.1661e+00,  2.0605e+00,  ..., -1.1971e+00,\n",
       "           1.4622e+00, -1.6735e+00],\n",
       "         [-1.5687e-01, -2.7467e-01, -6.0562e-01,  ..., -4.6049e-01,\n",
       "          -7.0813e-01,  4.4888e-01]],\n",
       "\n",
       "        [[-5.8475e-01, -1.1884e+00,  1.0000e+00,  ...,  1.7784e+00,\n",
       "           7.1668e-01,  3.7977e-01],\n",
       "         [ 1.2586e+00, -2.3768e-01,  8.9121e-01,  ..., -1.5840e+00,\n",
       "           2.4161e+00,  1.7169e+00],\n",
       "         [-4.3758e-01,  1.1050e+00,  8.4476e-01,  ..., -1.0575e+00,\n",
       "           5.5742e-01, -8.0408e-01],\n",
       "         ...,\n",
       "         [-1.1611e+00,  5.2250e-01,  9.2448e-01,  ..., -2.0682e+00,\n",
       "          -5.8583e-01, -1.9504e-01],\n",
       "         [ 1.1786e+00,  7.9430e-01,  1.1970e+00,  ..., -2.4030e-01,\n",
       "          -1.5818e+00, -3.9829e-01],\n",
       "         [ 9.4496e-02,  2.2312e+00, -4.3086e-01,  ..., -5.7904e-01,\n",
       "           7.8856e-02, -3.5618e-01]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiHeadAttention().forward(torch.randn(32, 64, 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
